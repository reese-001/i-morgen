<!DOCTYPE html>
<html>
	<head>
        <link rel="stylesheet" href="../styles.css">
		<title>i morgen</title>
		<link rel="icon" href="../images/logo.png">
	</head>
	<body>
<table>
			<tr>
				<td><img src="../images/logo.png" class="logo"></td>
				<td><h1 style="color:#0B2042;">i morgen</h1></td>
			</tr>
		</table>
        <h2 style="color:#0A45A5;"><a href="../../index.html">home</a>:<a href="../../aws/aws.html">aws</a>:<a href="index.html">kinesis</a>:overview</h2>

        <p><strong><span style="font-size: 20px;">Kinesis</span></strong></p>

        <p><strong><span style="font-size: 18px;">Contents</span>&nbsp;</strong></p>
        <li><a href="#what_is_it">What is it?</a></li>
        <li><a href="#data_streams">Kinesis Data Streams</a></li>
        <li><a href="#firehose">Firehose Delivery Stream</a></li>
        <li><a href="#video_streams">Video Streams</a></li>
        <li><a href="#data_analytics">Data Analytics</a></li>


        <div id="what_is_it">
            <p><strong><span style="font-size: 18px;">What is it?</span>&nbsp;</strong></p>
        </div>
        <ul>
            <li>Fully managed solution for collecting, processing and analyzing streaming data in the cloud</li>
            <li>Create data processing applications known as Kinesis Data Stream applications</li>
            <li>When you need real time, think Kinesis!</li>
            <li>Streaming data examples</li>
            <ul>
                <li>Stock prices</li>
                <li>Game data</li>
                <li>Social network data</li>
                <li>Geospatial data</li>
                <li>Click stream data</li>
            </ul>
        <li>There are four different kinds of Kinesis Streams</li>
        <ul>
            <li>Data Streams</li>
            <li>Firehose Delivery stream</li>
            <li>Data Analytics</li>
            <li>Video Analytics</li>
        </ul>
        </ul>   
       
        <div id="data_streams">
            <p><strong><span style="font-size: 18px;"><a href="images_data_stream.html">Kinesis Data Streams</a></span></strong></p>    
        </div>
        <ul>
            <li>Purpose: Stream big data in your system</li>
            <ul>
                <li>Stream consists of shards</li>
                <li>Shards are numbered (1, 2, 3, ..) and must be provisioned ahead of time</li>
                <li>Shards define your capacity and ingestion rates</li>
                <li>Pay per running shard</li>
            </ul>
            <li>Producers</li>
            <ul>
                <li>Examples</li>
                <ul>
                    <li>Applications</li>
                    <li>Clients</li>
                    <li>SDK, KPL (<a href="https://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html" target="_blank">Kinesis Producer Library</a>)</li>
                    <li>Kinesis Agent</li>
                </ul>
                
            </ul>
            <li>Producers send record into Kinesis</li>
            <ul>
                <li>Consists of</li>
                <ul>
                    <li>Partition Key</li>
                    <li>Data Blob (1 MB max)</li>
                </ul>
                <li>Partition key will help determine what shard it will land on</li>
                <li>Use PutRecord API from Producer to send into Kinesis </li>
                <ul>
                    <li>Consider batching to reduce costs and increase throughput</li>
                </ul>
                <li>Consider partition keys to avoid a "hot partition"</li>
                <ul>
                    <li>If incoming data rate exceeds capacity, you will get a "ProvisionedThroughputExceeded" error</li>
                    <li>In this case, re-evaluate your parition keys, implement retries with exponential backoff amd increase shards (scaling)</li>
                </ul>>
            </ul>
            <li>Kinesis sends record to consumers</li>
            <ul>
                <li>Consists of</li>
                <ul>
                    <li>Partition Key</li>
                    <li>Sequence Number</li>
                    <li>Data Blob</li>
                </ul>
                <li>There are two types of consumers</li>
                <ul>
                    <li>Shared (Classic) (Pull)</li>
                    <ul>
                        <li>Low number of consuming apps</li>
                        <li>Read throughput 2 MB/sec per shard across all consumers</li>
                        <li>Max 5 GetRecord API calls per second</li>
                        <li>Latency: 200ms</li>
                        <li>Poll data using GetRecords API</li>
                    </ul>
                    <li>Enhanced (Push)</li>
                    <ul>
                        <li>Multiple consuming applications for the same stream</li>
                        <li>2 MB per second per shard</li>
                        <li>Latency: 70ms</li>
                        <
                    </ul>
                </ul>
            </ul>
            <li>You can have multiple consumers and they must be manually configured</li>
            <ul>
                <li>Apps (KCL, SDK)</li>
                <li>Lambda</li>
                <li>Kinesis Data Firehose</li>
                <li>Kinesis Data Analytics</li>
            </ul>
            <li>Data persists for a predetermined time frame (24h default, 168h max - or is it 365 days? Conflicting info. TODO. )</li>
            <li>Typical use cases</li>
            <ul>
                <li>log and event data collection</li>
                <li>IoT device data capture</li>
                <li>mobile data collection</li>
                <li>gaming data feed</li>
            </ul>
        </ul>   

        <div id="firehose">
            <p><strong><span style="font-size: 18px;">Firehouse Delivery Stream</span></strong></p>    
        </div>
        <ul>
            <li>Choose one consumer from a predefined list that includes data lakes, data stores and analytics tools</li>
            <li>Delivers real-time streaming data to destinations such as</li>
            <ul>
                <li>Amazon Simple Storage Service (Amazon S3)</li>
                <li>Amazon Redshift</li>
                <li>Amazon Elasticsearch Service (Amazon ES). <a href="../images/kinesis_delivery_to_amazon_es.png">Process Flow</a></li>
                <li>Splunk</li>
            </ul> 
            <li>Data immediately disappears once its consumed</li>
            <li>You can convert incoming data to different formats, compress and secure</li>
            <li>You pay only for the data that is ingested</li>
            <li>You do not have to write code</li>
            <li>Typical use cases</li>
            <ul>
                <li>log and event data collection</li>
                <li>IoT device data capture</li>
                <li>clickstream</li>
                <li>security monitoring</li>
            </ul>
        </ul>  


        <div id="video_streams">
            <p><strong><span style="font-size: 18px;"><a href="images_video_stream.html">Video Streams</a></span></strong></p>    
        </div>
        <ul>
            <li>Ingest video and audio encoded data from various devices and services</li>
            <li>Output video data to ML or video processing services</li>
        </ul> 

        <div id="data_analytics">
            <p><strong><span style="font-size: 18px;">Data Analytics</span></strong></p>    
        </div>
        <ul>
            <li>Specify firehose or data streams as an input and an output</li>
            <li>Data that passes through the data analytics is run through custom SQL</li>
            <li>Output comes from your SQL and provides real time analytics</li>
            <li>Typical use cases</li>
            <ul>
                <li>real time streaming ETL</li>
                <li>real time log analysis</li>
                <li>ad tech and digital marketing analytics</li>
                <li>real time IoT device monitoring</li>
            </ul>
          
        </ul> 



    </body>
</html>
