<!DOCTYPE html>
<html>
	<head>
        <link rel="stylesheet" href="../styles.css">
		<title>i morgen</title>
		<link rel="icon" href="../images/logo.png">
	</head>
	<body>
<table>
			<tr>
				<td><img src="../images/logo.png" class="logo"></td>
				<td><h1 style="color:#0B2042;">i morgen</h1></td>
			</tr>
		</table>
        <h2 style="color:#0A45A5;"><a href="../../index.html">home</a>:<a href="../../aws/aws.html">aws</a>:<a href="index.html">kinesis</a>:overview</h2>

        <p><strong><span style="font-size: 20px;">Kinesis</span></strong></p>

        <p><strong><span style="font-size: 18px;">Contents</span>&nbsp;</strong></p>
        <li><a href="#what_is_it">What is it?</a></li>
        <li><a href="#kinesis_streams">Kinesis Streams</a></li>
        <li><a href="#data_streams">Kinesis Data Streams</a></li>
        <li><a href="#firehose">Firehose Delivery Stream</a></li>
        <li><a href="#video_streams">Video Streams</a></li>
        <li><a href="#data_analytics">Data Analytics</a></li>


        <div id="what_is_it">
            <p><strong><span style="font-size: 18px;">What is it?</span>&nbsp;</strong></p>
        </div>
        <ul>
            <li>Fully managed solution for collecting, processing and analyzing streaming data in the cloud - alternative to Apache Kafka</li>
            <li>Create data processing applications known as Kinesis Data Stream applications</li>
            <li>Replicated synchronously to 3 AZ's </li>
            <li>When you need real time, think Kinesis</li>
            <li>Streaming data examples</li>
            <ul>
                <li>Streaming processing frameworks</li>
                <ul>
                    <li>Spark</li>
                    <li>NiFi</li>
                </ul>
                <li>Stock prices</li>
                <li>Game data</li>
                <li>Social network data</li>
                <li>Geospatial data</li>
                <li>Click stream data</li>
            </ul>
            <li>There are four different kinds of Kinesis Streams</li>
            <ul>
                <li>Data Streams: low latency streaming ingest at scale</li>
                <li>Firehose Delivery stream: load streams into S3, Redshift, ElasticSearch and Splunk</li>
                <li>Data Analytics: perform real time analytics on streams using SQL</li>
                <li>Video Analytics: meant for streaming video in real time</li>
            </ul>
            <li>Sample Architecture</li>
            <ul>
                <li>[click streams, IoT devices, metrics and logs]  -->  Kinesis Streams  -->  Kinesis Analytics  -->  Kinesis Firehose  -->  [S3, Redshift]</li>
            </ul>
        </ul>  
        
        <br/>
        <div id="kinesis_streams">
            <p><strong><span style="font-size: 18px;">Kinesis Streams</span>&nbsp;</strong></p>
        </div>
        <ul>
            <li>Purpose: Stream big data in your system</li>
            <li>Streams consist of shards and partitions</li>
            <ul>
                <li>Shards are numbered (1, 2, 3, ..) and must be provisioned ahead of time</li>
                <li>Shards define your capacity and ingestion rates</li>
            </ul>
            <li>Charactoristics of stream</li>
            <ul>
                <li>Data retention is 24 hours by default with a max retention of 365 days</li>
                <li>You can replay/reprocess this data within the retention period</li>
                <li>Pub/sub architecture - multiple apps can consume the same stream</li>
                <li>Once the data is inserted into Kinesis, it cannot be deleted (immutable)</li>
                <li>Records can be up to 1mb in size</li>
            </ul>
            <li>Capacity modes</li>
            <ul>
                <li>Provisioned mode</li>
                <ul>
                    <li>You chose the number of shards provisioned</li>
                    <ul>
                        <li>You can manually scale or use API</li>
                        <li>Each shard gets 1MB/s in (or 1000 records per second)</li>
                        <li>Each shard gets 2MB/s out (classic or enhanced fan out consumer)</li>
                        <li>Pay per shard per hour</li>
                    </ul>
                </ul>
                <li>On demand mode</li>
                <ul>
                    <li>No need to provision or manage the capacity </li>
                    <li>Default capacity provisioned (4Mb/s in or 4000 records per second)</li>
                    <li>Scales automatically based on observed throughput peak during the last 30 days</li>
                </ul>
            </ul>
            <li>Limits to know</li>
            <ul>
                <li>Producers</li>
                <ul>
                    <li>1MB/s for 1000 messages/s at write per shard</li>
                    <ul>
                        <li>If you exceed that limit, you will receive a "ProvisionedThroughputException"</li>
                    </ul>
                </ul>
                <li>Consumers</li>
                <ul>
                    <li>2MB/s at read per shard across all consumers</li>
                    <li>5 API calls per second per shard across all consumers</li>
                </ul>
                <li>What does this mean? If you want to scale, you must increase shards</li>
            </ul>
        </ul>
        
        <br/>
        <div id="k">
            <p><strong><span style="font-size: 18px;">Kinesis Streams</span>&nbsp;</strong></p>
        </div>
        <ul>
            <li></li>
        </ul>


            <li>Producers</li>
            <ul>
                <li>Examples</li>
                <ul>
                    <li>Applications</li>
                    <li>Clients</li>
                    <li>SDK, KPL (<a href="https://docs.aws.amazon.com/streams/latest/dev/developing-producers-with-kpl.html" target="_blank">Kinesis Producer Library</a>)</li>
                    <li>Kinesis Agent</li>
                </ul>
                
            </ul>
            <li>Producers send record into Kinesis</li>
            <ul>
                <li>Consists of</li>
                <ul>
                    <li>Partition Key</li>
                    <li>Data Blob (1 MB max)</li>
                </ul>
                <li>Partition key will help determine what shard it will land on</li>
                <li>Use PutRecord API from Producer to send into Kinesis </li>
                <ul>
                    <li>Consider batching to reduce costs and increase throughput</li>
                </ul>
                <li>Consider partition keys to avoid a "hot partition"</li>
                <ul>
                    <li>If incoming data rate exceeds capacity, you will get a "ProvisionedThroughputExceeded" error</li>
                    <li>In this case, re-evaluate your parition keys, implement retries with exponential backoff amd increase shards (scaling)</li>
                </ul>
            </ul>
            <li>Kinesis sends record to consumers</li>
            <ul>
                <li>Consists of</li>
                <ul>
                    <li>Partition Key</li>
                    <li>Sequence Number</li>
                    <li>Data Blob</li>
                </ul>
                <li>There are two types of consumers</li>
                <ul>
                    <li>Shared (Classic) (Pull)</li>
                    <ul>
                        <li>Low number of consuming apps</li>
                        <li>Read throughput 2 MB/sec per shard across all consumers</li>
                        <li>Max 5 GetRecord API calls per second</li>
                        <li>Latency: 200ms</li>
                        <li>Poll data using GetRecords API</li>
                    </ul>
                    <li>Enhanced (Push)</li>
                    <ul>
                        <li>Multiple consuming applications for the same stream</li>
                        <li>2 MB per second per shard</li>
                        <li>Latency: 70ms</li>
                 
                    </ul>
                </ul>
            </ul>
            <li>You can have multiple consumers and they must be manually configured</li>
            <ul>
                <li>Apps (KCL, SDK)</li>
                <li>Lambda</li>
                <li>Kinesis Data Firehose</li>
                <li>Kinesis Data Analytics</li>
            </ul>
            <li>Data persists for a predetermined time frame (24h default, max 365 days)</li>
    
        </ul>   

        <div id="firehose">
            <p><strong><span style="font-size: 18px;">Firehouse Delivery Stream</span></strong></p>    
        </div>
        <ul>
            <li>Choose one consumer from a predefined list that includes data lakes, data stores and analytics tools</li>
            <li>Delivers real-time streaming data to destinations such as</li>
            <ul>
                <li>Amazon Simple Storage Service (Amazon S3)</li>
                <li>Amazon Redshift</li>
                <li>Amazon Elasticsearch Service (Amazon ES). <a href="../images/kinesis_delivery_to_amazon_es.png">Process Flow</a></li>
                <li>Splunk</li>
            </ul> 
            <li>Data immediately disappears once its consumed</li>
            <li>You can convert incoming data to different formats, compress and secure</li>
            <li>You pay only for the data that is ingested</li>
            <li>You do not have to write code</li>
            <li>Typical use cases</li>
            <ul>
                <li>log and event data collection</li>
                <li>IoT device data capture</li>
                <li>clickstream</li>
                <li>security monitoring</li>
            </ul>
        </ul>  


        <div id="video_streams">
            <p><strong><span style="font-size: 18px;"><a href="images_video_stream.html">Video Streams</a></span></strong></p>    
        </div>
        <ul>
            <li>Ingest video and audio encoded data from various devices and services</li>
            <li>Output video data to ML or video processing services</li>
        </ul> 

        <div id="data_analytics">
            <p><strong><span style="font-size: 18px;">Data Analytics</span></strong></p>    
        </div>
        <ul>
            <li>Specify firehose or data streams as an input and an output</li>
            <li>Data that passes through the data analytics is run through custom SQL</li>
            <li>Output comes from your SQL and provides real time analytics</li>
            <li>Typical use cases</li>
            <ul>
                <li>real time streaming ETL</li>
                <li>real time log analysis</li>
                <li>ad tech and digital marketing analytics</li>
                <li>real time IoT device monitoring</li>
            </ul>
          
        </ul> 



    </body>
</html>
